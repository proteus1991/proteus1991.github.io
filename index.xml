<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xiaohong Liu</title>
    <link>https://proteus1991.github.io/</link>
    <description>Recent content on Xiaohong Liu</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Â©Xiaohong Liu</copyright>
    <lastBuildDate>Wed, 13 May 2020 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://proteus1991.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Backpropagation</title>
      <link>https://proteus1991.github.io/post/backpropagation/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/post/backpropagation/</guid>
      <description>

&lt;h2 id=&#34;content&#34;&gt;Content&lt;/h2&gt;

&lt;p&gt;&lt;p align=&#34;justify&#34;&gt;This post is to introduce the backpropagation in details. Backpropagation, in other words, is based on total differential formula and chain rule, which has a forward pass and a backward pass. The gradient for each weight (w&lt;sub&gt;i&lt;/sub&gt;) is obtained by multiplying the partial derivatives from two passes.&lt;/p&gt;

&lt;p&gt;Reference: &lt;a href=&#34;./lecture.pdf&#34;&gt;Backpropagation slides&lt;/a&gt;.
Note credit: &lt;a href=&#34;https://sakura-gh.github.io/ML-notes/ML-notes-html/9_Backpropagation.html&#34; target=&#34;_blank&#34;&gt;Sakura-gh&lt;/a&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&#34;./figures/Chain_Rule-1.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/Chain_Rule-2.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/Backpropagation-1.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/Backpropagation-2.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/Backpropagation-3.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/Backpropagation-4.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/Backpropagation-5.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/Backpropagation-6.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Optimization Methods in Deep Learning</title>
      <link>https://proteus1991.github.io/post/optimization-in-dl/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/post/optimization-in-dl/</guid>
      <description>

&lt;h2 id=&#34;content&#34;&gt;Content&lt;/h2&gt;

&lt;p&gt;&lt;p align=&#34;justify&#34;&gt;This post is to sort out the optimization methods in deep learning from the most basic idea about what is &lt;b&gt;gradient descent&lt;/b&gt; to the most popular optimizer - &lt;b&gt;Adam&lt;/b&gt;. Moreoever, the &lt;b&gt;SGD&lt;/b&gt;, &lt;b&gt;SGDM&lt;/b&gt;, &lt;b&gt;Adagrad&lt;/b&gt;, &lt;b&gt;PMSProp&lt;/b&gt; and some recent advances such as &lt;b&gt;AdamW&lt;/b&gt; are introduced. Hope this post could give me some hints about how to choose different optimizers to train the neural network.&lt;/p&gt;

&lt;p&gt;Reference: &lt;a href=&#34;./lecture.pdf&#34;&gt;Optimization slides&lt;/a&gt;, &lt;a href=&#34;./tutorial.pdf&#34;&gt;Tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&#34;./figures/optimization-1.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 1&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/optimization-2.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 2&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/optimization-3.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 3&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/optimization-4.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 4&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/optimization-5.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 5&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./figures/optimization-6.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 6&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>Generative Adversarial Network (GAN)</title>
      <link>https://proteus1991.github.io/post/gan/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/post/gan/</guid>
      <description>

&lt;h2 id=&#34;content&#34;&gt;Content&lt;/h2&gt;

&lt;p align=&#34;justify&#34;&gt;This post is about my understanding of &lt;b&gt;generative adversarial network (GAN)&lt;/b&gt;, including what is GAN, the derivation of basic theory, and GAN&#39;s general framework. In addition, the &lt;b&gt;conditional GANs&lt;/b&gt; with supervised and unsupervised learning are exhaustively introduced. After that, several representative GAN methods are discussed including, among others, &lt;b&gt;WGAN, EBGAN, InfoGAN, VAEGAN, and BiGAN&lt;/b&gt;. Finally, several applications of GAN are mentioned including photo editing and sequence generation, where some basic ideas and derivation of reinforcement learning are provided. &lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-01.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 1&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-02.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 2&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-03.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 3&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-04.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 4&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-05.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 5&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-06.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 6&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-07.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 7&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-08.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 8&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-09.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 9&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-10.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 10&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-11.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 11&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-12.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 12&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-13.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 13&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-14.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 14&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;figure&gt;
  &lt;img src=&#34;./GAN/GAN-15.png&#34; alt=&#34;Trulli&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;center&gt;Page 15&lt;center&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title>End-To-End Trainable Video Super-Resolution Based on a New Mechanism for Implicit Motion Estimation and Compensation</title>
      <link>https://proteus1991.github.io/publication/wacv2020/</link>
      <pubDate>Mon, 09 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/publication/wacv2020/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;

&lt;!-- Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>GridDehazeNet: Attention-Based Multi-Scale Network for Image Dehazing</title>
      <link>https://proteus1991.github.io/publication/iccv2019/</link>
      <pubDate>Mon, 22 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/publication/iccv2019/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;

&lt;!-- Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;







&lt;figure&gt;

  &lt;a data-fancybox=&#34;&#34; href=&#34;figure1.png&#34; &gt;

&lt;img src=&#34;figure1.png&#34; &gt;
&lt;/a&gt;

&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Amazon Winner Strategy Project</title>
      <link>https://proteus1991.github.io/project/price_recommendation/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/project/price_recommendation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image Retrieval via Canonical Correlation Analysis</title>
      <link>https://proteus1991.github.io/publication/cwit2019/</link>
      <pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/publication/cwit2019/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;

&lt;!-- Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Video Super-Resolution via Dynamic Local Filter Network</title>
      <link>https://proteus1991.github.io/publication/globalsip2018/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/publication/globalsip2018/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;

&lt;!-- Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Robust Multi-Frame Super-Resolution Based on Spatially Weighted Half-Quadratic Estimation and Adaptive BTV Regularization</title>
      <link>https://proteus1991.github.io/publication/tip2018/</link>
      <pubDate>Fri, 15 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/publication/tip2018/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;

&lt;!-- Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Robust multi-frame super-resolution with adaptive norm choice and difference curvature based BTV regularization</title>
      <link>https://proteus1991.github.io/publication/globalsip2017/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://proteus1991.github.io/publication/globalsip2017/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Slides&lt;/em&gt; button above to demo Academic&amp;rsquo;s Markdown slides feature.
  &lt;/div&gt;
&lt;/div&gt;
 --&gt;

&lt;!-- Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
  </channel>
</rss>
