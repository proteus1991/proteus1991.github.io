[{"authors":["admin"],"categories":null,"content":"I’m a Ph.D. candidate at McMaster University supervised by Dr. Jun Chen. My research directions are aimed at computer vision, machine learning and deep learning, especially in areas of image and video restoration, retrieval, classification and recognition.\n","date":1585612800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1585612800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://proteus1991.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I’m a Ph.D. candidate at McMaster University supervised by Dr. Jun Chen. My research directions are aimed at computer vision, machine learning and deep learning, especially in areas of image and video restoration, retrieval, classification and recognition.","tags":null,"title":"Xiaohong Liu","type":"authors"},{"authors":["Xiaohong Liu"],"categories":[],"content":" Content This post is about my understanding of generative adversarial network (GAN), including what is GAN, the derivation of basic theory, and GAN's general framework. In addition, the conditional GANs with supervised and unsupervised learning are exhaustively introduced. After that, several representative GAN methods are discussed including, among others, WGAN, EBGAN, InfoGAN, VAEGAN, and BiGAN. Finally, several applications of GAN are mentioned including photo editing and sequence generation, where some basic ideas and derivation of reinforcement learning are provided.  Page 1   Page 2   Page 3   Page 4   Page 5   Page 6   Page 7   Page 8   Page 9   Page 10   Page 11   Page 12   Page 13   Page 14   Page 15  ","date":1585612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585612800,"objectID":"cf2bf6beb32d4133b075c3f3e2208511","permalink":"https://proteus1991.github.io/post/gan/","publishdate":"2020-03-31T00:00:00Z","relpermalink":"/post/gan/","section":"post","summary":"A review of Generative Adversarial Network","tags":[],"title":"Generative Adversarial Network (GAN)","type":"post"},{"authors":["Xiaohong Liu","Lingshi Kong","Yang Zhou","Jiying Zhao","Jun Chen"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1575849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575849600,"objectID":"bd8f35230e75e3b4c1318a11ec31638a","permalink":"https://proteus1991.github.io/publication/wacv2020/","publishdate":"2019-12-09T00:00:00Z","relpermalink":"/publication/wacv2020/","section":"publication","summary":"Video super-resolution aims at generating a high-resolution video from its low-resolution counterpart. With the rapid rise of deep learning, many recently proposed video super-resolution methods use convolutional neural networks in conjunction with explicit motion compensation to capitalize on statistical dependencies within and across low-resolution frames. Two common issues of such methods are noteworthy. Firstly, the quality of the final reconstructed HR video is often very sensitive to the accuracy of motion estimation. Secondly, the warp grid needed for motion compensation, which is specified by the two flow maps delineating pixel displacements in horizontal and vertical directions, tends to introduce additional errors and jeopardize the temporal consistency across video frames. To address these issues, we propose a novel dynamic local filter network to perform implicit motion estimation and compensation by employing, via locally connected layers, sample-specific and position-specific dynamic local filters that are tailored to the target pixels. We also propose a global refinement network based on ResBlock and autoencoder structures to exploit non-local correlations and enhance the spatial consistency of super-resolved frames. The experimental results demonstrate that the proposed method outperforms the state-of-the-art, and validate its strength in terms of local transformation handling, temporal consistency as well as edge sharpness.","tags":["Video Super-Resolution"],"title":"End-To-End Trainable Video Super-Resolution Based on a New Mechanism for Implicit Motion Estimation and Compensation","type":"publication"},{"authors":["Xiaohong Liu","Mayong Rui","Zhihao Shi","Jun Chen"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   --    ","date":1563753600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563753600,"objectID":"d9c1b180bd8d27037a1fceb80b7a3d80","permalink":"https://proteus1991.github.io/publication/iccv2019/","publishdate":"2019-07-22T00:00:00Z","relpermalink":"/publication/iccv2019/","section":"publication","summary":"We propose an end-to-end trainable Convolutional Neural Network (CNN), named GridDehazeNet, for single image dehazing. The GridDehazeNet consists of three modules: pre-processing, backbone, and post-processing. The trainable pre-processing module can generate learned inputs with better diversity and more pertinent features as compared to those derived inputs produced by hand-selected pre-processing methods. The backbone module implements a novel attention-based multi-scale estimation on a grid network, which can effectively alleviate the bottleneck issue often encountered in the conventional multi-scale approach. The post-processing module helps to reduce the artifacts in the final output. Experimental results indicate that the GridDehazeNet outperforms the state-of-the-arts on both synthetic and real-world images. The proposed hazing method does not rely on the atmosphere scattering model, and we provide an explanation as to why it is not necessarily beneficial to take advantage of the dimension reduction offered by the atmosphere scattering model for image dehazing, even if only the dehazing results on synthetic images are concerned.","tags":["Image Dehazing"],"title":"GridDehazeNet: Attention-Based Multi-Scale Network for Image Dehazing","type":"publication"},{"authors":null,"categories":null,"content":"","date":1560643200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560643200,"objectID":"f0faf90c026fa38f9773244cfd73cf9d","permalink":"https://proteus1991.github.io/project/price_recommendation/","publishdate":"2019-06-16T00:00:00Z","relpermalink":"/project/price_recommendation/","section":"project","summary":"A neural network is devloped to recommend the best parameter combination (e.g. the optimal price-cost tradeoff) that maximizes the chance of winning the competition against other companies.","tags":["Deep Learning"],"title":"Amazon Winner Strategy Project","type":"project"},{"authors":["Kangdi Shi","Xiaohong Liu","Muhammad Alrabeiah","Xintong Guo","Jie Lin","Huan Liu","Jun Chen"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1559433600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559433600,"objectID":"9999a787af7fb867844a1df90ffdee49","permalink":"https://proteus1991.github.io/publication/cwit2019/","publishdate":"2019-12-12T00:00:00Z","relpermalink":"/publication/cwit2019/","section":"publication","summary":"Canonical Correlation Analysis (CCA) is a powerful multivariate statistical method. It can be used to find, for a given dimension, a projection pair that maximally captures the correlation between two target random vectors. This work introduces a CCA-based approach for image retrieval. It capitalizes on feature maps extracted from a pre-trained Convolutional Neural Network (CNN) and leverages basis vectors identified via CCA, in conjunction with an element-wise selection method based on the Chernoff information, to generate compact transformed image features; the level of similarity between two images is determined by a hypothesis test regarding the joint distribution of transformed feature pair. The proposed approach is benchmarked against two popular statistical analysis methods, Linear Discriminant Analysis (LDA) and Principal Component Analysis with whitening (PCAw). The CCA approach is shown to achieve competitive retrieval performances on popular datasets such as Oxford5k and Paris6k.","tags":["Image Retrieval"],"title":"Image Retrieval via Canonical Correlation Analysis","type":"publication"},{"authors":["Yang Zhou","Xiaohong Liu","Lei Chen","Jiying Zhao"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1543190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543190400,"objectID":"6172824e8eccb1a348d3e9a4182df35b","permalink":"https://proteus1991.github.io/publication/globalsip2018/","publishdate":"2018-11-26T00:00:00Z","relpermalink":"/publication/globalsip2018/","section":"publication","summary":"Conventional Convolutional Neural Network (CNN) based video super-resolution (VSR) methods heavily depend on explicit motion compensation. Input frames are warped according to flow-like information to eliminate inter-frame differences. These methods have to make a trade-off between the distraction caused by spatio-temporal inconsistency and the pixel-wise detail damage caused by compensation. In this paper, we propose a novel video super-resolution method based on dynamic local filter network. Unlike traditional VSR techniques, our method implicitly performs motion estimation, compensation and fusion simultaneously via local convolutions with dynamically generated filter kernels. An optional autoencoder based refinement module is also proposed to sharpen edges and remove artifacts. The experimental results demonstrate that our method outperforms the best existing VSR algorithm by 0.53 dB in terms of PSNR, and provides superior visual quality.","tags":["Video Super-Resolution"],"title":"Video Super-Resolution via Dynamic Local Filter Network","type":"publication"},{"authors":["Xiaohong Liu","Wenyi Wang","Lei Chen","Jiying Zhao"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1529020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529020800,"objectID":"f1631c65791a43dd5addf3721a5aeb17","permalink":"https://proteus1991.github.io/publication/tip2018/","publishdate":"2018-06-15T00:00:00Z","relpermalink":"/publication/tip2018/","section":"publication","summary":"Multi-frame image super-resolution focuses on reconstructing a high-resolution image from a set of low-resolution images with high similarity. Combining image prior knowledge with fidelity model, the Bayesian-based methods have been considered as an effective technique in super-resolution. The minimization function derived from maximum a posteriori probability (MAP) is composed of a fidelity term and a regularization term. In this paper, based on the MAP estimation, we propose a novel initialization method for super-resolution imaging. For the fidelity term in our proposed method, the half-quadratic estimation is used to choose error norm adaptively instead of using fixed L 2 norms. Besides, a spatial weight matrix is used as a confidence map to scale the estimation result. For the regularization term, we propose a novel regularization method based on adaptive bilateral total variation (ABTV). Both the fidelity term and the ABTV regularization guarantee the robustness of our framework. The fidelity term is mainly responsible for dealing with misregistration, blur, and other kinds of large errors, while the ABTV regularization aims at edge preservation and noise removal. The proposed scheme is tested on both synthetic data and real data. The experimental results illustrate the superiority of our proposed method in terms of edge preservation and noise removal over the state-of-the-art algorithms.","tags":["Multi-Frame Super-Resolution"],"title":"Robust Multi-Frame Super-Resolution Based on Spatially Weighted Half-Quadratic Estimation and Adaptive BTV Regularization","type":"publication"},{"authors":["Xiaohong Liu","Jiying Zhao"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   -- ","date":1510617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510617600,"objectID":"f4fc00abea6ad532f8cc48ac25269dc6","permalink":"https://proteus1991.github.io/publication/globalsip2017/","publishdate":"2017-11-14T00:00:00Z","relpermalink":"/publication/globalsip2017/","section":"publication","summary":"Multi-frame super-resolution focuses on reconstructing a high-resolution image from a set of low-resolution images with high similarity. The minimization function derived from maximum a posteriori probability (MAP) is composed of a fidelity term and a regularization term. In this paper, we propose a new fidelity term based on half-quadratic estimation to choose error norm adaptively instead of using fixed L1 or L2 norm. Besides, we propose a novel regularization method which combines the advantage of Difference Curvature (DC) and Bilateral Total Variation (BTV) to preserve the edge areas and remove noise simultaneously. The proposed framework is tested on both synthetic data and real data. Our experimental results illustrate the superiority of the proposed method in terms of edge preserving and noise removal over other state-of-the-art algorithms.","tags":["Multi-Frame Super-Resolution"],"title":"Robust multi-frame super-resolution with adaptive norm choice and difference curvature based BTV regularization","type":"publication"}]